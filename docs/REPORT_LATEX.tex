\documentclass[a4paper,13pt,3p,twoside]{report}
\usepackage{scrextend}
\changefontsizes{13pt}
\usepackage[utf8]{vietnam}
\usepackage[top=2cm, bottom=2cm, left=3.5cm, right=2.5cm]{geometry}

\usepackage{graphicx} % Cho phép chèn hỉnh ảnh
\usepackage{fancybox} % Tạo khung box
\usepackage{indentfirst} % Thụt đầu dòng ở dòng đầu tiên trong đoạn
\usepackage{amsthm} % Cho phép thêm các môi trường định nghĩa
\usepackage{latexsym} % Các kí hiệu toán học
\usepackage{amsmath} % Hỗ trợ một số biểu thức toán học
\usepackage{amssymb} % Bổ sung thêm kí hiệu về toán học
\usepackage{amsbsy} % Hỗ trợ các kí hiệu in đậm
\usepackage{times} % Chọn font Time New Romans
\usepackage{array} % Tạo bảng array
\usepackage{enumitem} % Cho phép thay đổi kí hiệu của list
\usepackage{subfiles} % Chèn các file nhỏ, giúp chia các chapter ra nhiều file hơn
\usepackage{titlesec} % Giúp chỉnh sửa các tiêu đề, đề mục như chương, phần,..
\usepackage{titletoc}
\usepackage{chngcntr} % Dùng để thiết lập lại cách đánh số caption,..
\usepackage{pdflscape} % Đưa các bảng có kích thước đặt theo chiều ngang giấy
\usepackage{afterpage}
\usepackage[ruled,vlined]{algorithm2e}  % Hỗ trợ viết các giải thuật
\usepackage{capt-of} % Cho phép sử dụng caption lớn đối với landscape page
\usepackage{multirow} % Merge cells
\usepackage{fancyhdr} % Cho phép tùy biến header và footer
% \usepackage[natbib,backend=biber,style=ieee]{biblatex} % Giúp chèn tài liệu tham khảo
\usepackage{appendix}

\usepackage[font=small,labelfont=bf]{caption}

\usepackage{listings}
\usepackage{xcolor}
\usepackage{float}
\usepackage{subcaption}
\usepackage{xurl}

% ===================================================
% CẤU HÌNH CODE BLOCKS
% ===================================================
\definecolor{codegreen}{rgb}{0,0.6,0}
\definecolor{codegray}{rgb}{0.5,0.5,0.5}
\definecolor{codepurple}{rgb}{0.58,0,0.82}
\definecolor{backcolour}{rgb}{0.95,0.95,0.92}
\definecolor{keywordcolor}{rgb}{0.0,0.0,0.7}

\lstdefinestyle{mystyle}{
    backgroundcolor=\color{backcolour},
    commentstyle=\color{codegreen},
    keywordstyle=\color{keywordcolor}\bfseries,
    numberstyle=\tiny\color{codegray},
    stringstyle=\color{codepurple},
    basicstyle=\ttfamily\footnotesize,
    breakatwhitespace=false,
    breaklines=true,
    captionpos=b,
    keepspaces=true,
    numbers=left,
    numbersep=5pt,
    showspaces=false,
    showstringspaces=false,
    showtabs=false,
    tabsize=2,
    frame=single,
    framerule=0.5pt,
    rulecolor=\color{codegray},
    xleftmargin=15pt,
    framexleftmargin=15pt,
    aboveskip=10pt,
    belowskip=10pt,
    inputencoding=utf8,
    extendedchars=true,
    literate=
        {á}{{\'a}}1 {à}{{\`a}}1 {ả}{{\h{a}}}1 {ã}{{\~a}}1 {ạ}{{\d{a}}}1
        {ă}{{\u{a}}}1 {ắ}{{\'\u{a}}}1 {ằ}{{\`\u{a}}}1 {ẳ}{{\h{\u{a}}}}1 {ẵ}{{\~\u{a}}}1 {ặ}{{\d{\u{a}}}}1
        {â}{{\^a}}1 {ấ}{{\'\^a}}1 {ầ}{{\`\^a}}1 {ẩ}{{\h{\^a}}}1 {ẫ}{{\~\^a}}1 {ậ}{{\d{\^a}}}1
        {é}{{\'e}}1 {è}{{\`e}}1 {ẻ}{{\h{e}}}1 {ẽ}{{\~e}}1 {ẹ}{{\d{e}}}1
        {ê}{{\^e}}1 {ế}{{\'\^e}}1 {ề}{{\`\^e}}1 {ể}{{\h{\^e}}}1 {ễ}{{\~\^e}}1 {ệ}{{\d{\^e}}}1
        {í}{{\'i}}1 {ì}{{\`i}}1 {ỉ}{{\h{i}}}1 {ĩ}{{\~i}}1 {ị}{{\d{i}}}1
        {ó}{{\'o}}1 {ò}{{\`o}}1 {ỏ}{{\h{o}}}1 {õ}{{\~o}}1 {ọ}{{\d{o}}}1
        {ô}{{\^o}}1 {ố}{{\'\^o}}1 {ồ}{{\`\^o}}1 {ổ}{{\h{\^o}}}1 {ỗ}{{\~\^o}}1 {ộ}{{\d{\^o}}}1
        {ơ}{{\horn{o}}}1 {ớ}{{\'\horn{o}}}1 {ờ}{{\`\horn{o}}}1 {ở}{{\h{\horn{o}}}}1 {ỡ}{{\~\horn{o}}}1 {ợ}{{\d{\horn{o}}}}1
        {ú}{{\'u}}1 {ù}{{\`u}}1 {ủ}{{\h{u}}}1 {ũ}{{\~u}}1 {ụ}{{\d{u}}}1
        {ư}{{\horn{u}}}1 {ứ}{{\'\horn{u}}}1 {ừ}{{\`\horn{u}}}1 {ử}{{\h{\horn{u}}}}1 {ữ}{{\~\horn{u}}}1 {ự}{{\d{\horn{u}}}}1
        {ý}{{\'y}}1 {ỳ}{{\`y}}1 {ỷ}{{\h{y}}}1 {ỹ}{{\~y}}1 {ỵ}{{\d{y}}}1
        {đ}{{\dj}}1
        {Á}{{\'A}}1 {À}{{\`A}}1 {Ả}{{\h{A}}}1 {Ã}{{\~A}}1 {Ạ}{{\d{A}}}1
        {Ă}{{\u{A}}}1 {Ắ}{{\'\u{A}}}1 {Ằ}{{\`\u{A}}}1 {Ẳ}{{\h{\u{A}}}}1 {Ẵ}{{\~\u{A}}}1 {Ặ}{{\d{\u{A}}}}1
        {Â}{{\^A}}1 {Ấ}{{\'\^A}}1 {Ầ}{{\`\^A}}1 {Ẩ}{{\h{\^A}}}1 {Ẫ}{{\~\^A}}1 {Ậ}{{\d{\^A}}}1
        {É}{{\'E}}1 {È}{{\`E}}1 {Ẻ}{{\h{E}}}1 {Ẽ}{{\~E}}1 {Ẹ}{{\d{E}}}1
        {Ê}{{\^E}}1 {Ế}{{\'\^E}}1 {Ề}{{\`\^E}}1 {Ể}{{\h{\^E}}}1 {Ễ}{{\~\^E}}1 {Ệ}{{\d{\^E}}}1
        {Í}{{\'I}}1 {Ì}{{\`I}}1 {Ỉ}{{\h{I}}}1 {Ĩ}{{\~I}}1 {Ị}{{\d{I}}}1
        {Ó}{{\'O}}1 {Ò}{{\`O}}1 {Ỏ}{{\h{O}}}1 {Õ}{{\~O}}1 {Ọ}{{\d{O}}}1
        {Ô}{{\^O}}1 {Ố}{{\'\^O}}1 {Ồ}{{\`\^O}}1 {Ổ}{{\h{\^O}}}1 {Ỗ}{{\~\^O}}1 {Ộ}{{\d{\^O}}}1
        {Ơ}{{\horn{O}}}1 {Ớ}{{\'\horn{O}}}1 {Ờ}{{\`\horn{O}}}1 {Ở}{{\h{\horn{O}}}}1 {Ỡ}{{\~\horn{O}}}1 {Ợ}{{\d{\horn{O}}}}1
        {Ú}{{\'U}}1 {Ù}{{\`U}}1 {Ủ}{{\h{U}}}1 {Ũ}{{\~U}}1 {Ụ}{{\d{U}}}1
        {Ư}{{\horn{U}}}1 {Ứ}{{\'\horn{U}}}1 {Ừ}{{\`\horn{U}}}1 {Ử}{{\h{\horn{U}}}}1 {Ữ}{{\~\horn{U}}}1 {Ự}{{\d{\horn{U}}}}1
        {Ý}{{\'Y}}1 {Ỳ}{{\`Y}}1 {Ỷ}{{\h{Y}}}1 {Ỹ}{{\~Y}}1 {Ỵ}{{\d{Y}}}1
        {Đ}{{\DJ}}1
}

\lstset{style=mystyle}

% Định nghĩa ngôn ngữ Python
\lstdefinelanguage{Python}{
    keywords={def, class, return, if, else, elif, for, while, import, from, as, try, except, with, True, False, None, and, or, not, in, is, lambda, yield, pass, break, continue, global, nonlocal, assert, raise, finally},
    keywordstyle=\color{keywordcolor}\bfseries,
    ndkeywords={self, cls, int, str, list, dict, tuple, set, float, bool, bytes},
    ndkeywordstyle=\color{codepurple}\bfseries,
    sensitive=true,
    comment=[l]{\#},
    morecomment=[s]{'''}{'''},
    morecomment=[s]{"""}{"""}, 
    morestring=[b]',
    morestring=[b]"
}

\usepackage[nonumberlist, nopostdot, nogroupskip, acronym]{glossaries}
\usepackage{glossary-superragged}
\setglossarystyle{superraggedheaderborder}
\usepackage{setspace}
\usepackage{parskip}

% package content table
\usepackage{tocbasic}

\usepackage{blindtext}


% ===================================================

\renewcommand{\bibname}{Danh_sach_tai_lieu_tham_khao} 
\usepackage[backend=bibtex,style=ieee]{biblatex}  %backend=biber is 'better'

\renewcommand\appendixname{PHỤ LỤC}
\renewcommand\appendixpagename{PHỤ LỤC}
\renewcommand\appendixtocname{PHỤ LỤC}


\addbibresource{Danh_sach_tai_lieu_tham_khao.bib} % chèn file chứa danh mục tài liệu tham khảo vào 

\include{lstlisting} % Phần này cho phép chèn code và formatting code như C, C++, Python

% ===================================================


\fancypagestyle{plain}{%
\fancyhf{} % clear all header and footer fields
\fancyfoot[RO,RE]{\thepage} %RO=right odd, RE=right even
\renewcommand{\headrulewidth}{0pt}
\renewcommand{\footrulewidth}{0pt}}

\setlength{\headheight}{10pt}

\def \TITLE{ĐỒ ÁN TỐT NGHIỆP}
\def \AUTHOR{NGUYỄN VĂN ABC}

% ===================================================
\titleformat{\chapter}[hang]{\centering\bfseries}{CHƯƠNG \thechapter.\ }{0pt}{}[]

\titleformat 
    {\chapter} % command
    [hang] % shape
    {\centering\bfseries} % format
    {CHƯƠNG \thechapter.\ } % label
    {0pt} %sep
    {} % before
    [] % after
\titlespacing*{\chapter}{0pt}{-20pt}{20pt}

\titleformat
    {\section} % command
    [hang] % shape
    {\bfseries} % format
    {\thechapter.\arabic{section}\ \ \ \ } % label
    {0pt} %sep
    {} % before
    [] % after
\titlespacing{\section}{0pt}{\parskip}{0.5\parskip}

\titleformat
    {\subsection} % command
    [hang] % shape
    {\bfseries} % format
    {\thechapter.\arabic{section}.\arabic{subsection}\ \ \ \ } % label
    {0pt} %sep
    {} % before
    [] % after
\titlespacing{\subsection}{30pt}{\parskip}{0.5\parskip}

\renewcommand\thesubsubsection{\alph{subsubsection}}
\titleformat
    {\subsubsection} % command
    [hang] % shape
    {\bfseries} % format
    {\alph{subsubsection}, \ } % label
    {0pt} %sep
    {} % before
    [] % after
\titlespacing{\subsubsection}{50pt}{\parskip}{0.5\parskip}

% \newcommand{\titlesize}{\fontsize{18pt}{23pt}\selectfont}
% \newcommand{\subtitlesize}{\fontsize{16pt}{21pt}\selectfont}
% \titleclass{\part}{top}
% \titleformat{\part}[display]
%   {\normalfont\huge\bfseries}{\centering}{20pt}{\Huge\centering}
% \titlespacing{\part}{0pt}{em}{1em}
% \titlespacing{\section}{0pt}{\parskip}{0.5\parskip}
% \titlespacing{\subsection}{0pt}{\parskip}{0.5\parskip}
% \titlespacing{\subsubsection}{0pt}{\parskip}{0.5\parskip}



% ===================================================
\usepackage{hyperref}
\hypersetup{pdfborder = {0 0 0}} %
\hypersetup{pdftitle={\TITLE},
	pdfauthor={\AUTHOR}}
	
\usepackage[all]{hypcap} % Cho phép tham chiếu chính xác đến hình ảnh và bảng biểu

\graphicspath{{figures/}{../figures/}} % Thư mục chứa các hình ảnh

\counterwithin{figure}{chapter} % Đánh số hình ảnh kèm theo chapter. Ví dụ: Hình 1.1, 1.2,..

\title{\bf \TITLE}
\author{\AUTHOR}

\setcounter{secnumdepth}{3} % Cho phép subsubsection trong report
% \setcounter{tocdepth}{3} % Chèn subsubsection vào bảng mục lục

\theoremstyle{definition}
\newtheorem{example}{Ví dụ}[chapter] % Định nghĩa môi trường ví dụ

\onehalfspacing
%Khoảng cách xuống dòng
\setlength{\parskip}{6pt}
%Lùi đầu dòng
\setlength{\parindent}{15pt}

% ===================================================
% BẮT ĐẦU TÀI LIỆU
% ===================================================

\begin{document}

% ===================================================
% TRANG BÌA
% ===================================================
\begin{titlepage}
\thispagestyle{empty}
\begin{center}

{\textbf{\large{ĐẠI HỌC BÁCH KHOA HÀ NỘI}}}\\[4cm]

{\textbf{\huge{BÁO CÁO ĐỒ ÁN GR2}}}\\[1cm]
{\textbf{\Large{Hệ thống RAG tư vấn pháp luật tài chính Nhật Bản cho người Việt Nam}}}\\[1cm]

{\textbf{\large{PHẠM GIA CƯỜNG}}}\\[0.2cm]
{\large{cuong.pg210886@sis.hust.edu.vn}}\\[0.5cm]

{\textbf{\large{Chương trình đào tạo: Công nghệ thông tin Việt-Nhật}}}\\[0.2cm]

\vspace{4cm}
\begin{table}[H]
\centering
\resizebox{\textwidth}{!}{%
\begin{tabular}{ll}
 \multicolumn{1}{c}{\textbf{Giảng viên hướng dẫn:}} & TS. Phạm Văn Tiến \hspace{0.5cm}
  \\[0.5cm]
 \multicolumn{1}{l}{\textbf{Khoa:}} & Kỹ thuật máy tính \hspace{0.5cm} \\ [0.5cm]
 \multicolumn{1}{l}{\textbf{Trường:}} & Công nghệ thông tin và Truyền thông \hspace{0.5cm} \\ [4.5cm]
\multicolumn{2}{c}{\textbf{HÀ NỘI, 01/2026}}                                            
\end{tabular}%
}
\end{table}
\end{center}
\end{titlepage}

% ===================================================
% MỤC LỤC
% ===================================================
\tableofcontents
\newpage

% ===================================================
% CHƯƠNG 1: GIỚI THIỆU
% ===================================================
\chapter{GIỚI THIỆU}

\section{Bối cảnh và động lực}

Đồ án này xuất phát từ một quan sát thực tế về cộng đồng người Việt Nam tại Nhật Bản. Theo thống kê từ Bộ Tư pháp Nhật Bản tính đến cuối năm 2024, có hơn 500,000 người Việt đang sinh sống và làm việc tại đây, đứng thứ hai chỉ sau cộng đồng Trung Quốc. Nhu cầu tìm hiểu các quy định pháp luật tài chính của nước sở tại là rất lớn, nhưng rào cản ngôn ngữ và khả năng tiếp cận đang là vấn đề nghiêm trọng.

Vấn đề cốt lõi không phải là thiếu thông tin, mà nằm ở khả năng tiếp cận. Các văn bản pháp luật Nhật Bản được viết bằng ngôn ngữ pháp lý phức tạp với nhiều thuật ngữ chuyên ngành như 確定申告 (khai thuế cuối năm), 源泉徴収 (khấu trừ tại nguồn), hay 厚生年金 (bảo hiểm hưu trí). Ngay cả người Nhật bản địa cũng cần thời gian để hiểu những thuật ngữ này, đối với người nước ngoài thì đây gần như là một rào cản không nhỏ.

Câu hỏi nghiên cứu đặt ra là: liệu có thể xây dựng một hệ thống cho phép người Việt đặt câu hỏi bằng tiếng mẹ đẻ, tìm kiếm trong kho văn bản tiếng Nhật gốc theo ngữ nghĩa, và nhận được câu trả lời chính xác kèm trích dẫn nguồn pháp lý? Đây chính là động lực để em theo đuổi hướng tiếp cận Retrieval-Augmented Generation.

\section{Phân tích các phương pháp tiếp cận}

Trước khi quyết định sử dụng RAG, em đã phân tích kỹ ba hướng tiếp cận chính.

\subsection{Phương án 1: Fine-tuning LLM trên tập dữ liệu pháp luật}

Hướng này có ưu điểm là sau khi fine-tune, mô hình có thể trả lời các câu hỏi pháp lý mà không cần retrieval step. Tuy nhiên, có hai nhược điểm đáng kể. Thứ nhất là chi phí tính toán cao, fine-tuning một mô hình như Llama-2-7B hay GPT-3.5 yêu cầu GPU với VRAM lớn và thời gian training đáng kể. Thứ hai và quan trọng hơn, mô hình sau khi fine-tune sẽ bị "đóng băng" kiến thức tại thời điểm training. Trong lĩnh vực pháp lý, luật có thể được sửa đổi, bổ sung hàng năm, việc phải re-train mỗi khi có thay đổi là không khả thi.

\subsection{Phương án 2: Hệ thống tìm kiếm dựa trên từ khóa (BM25)}

Đây là cách tiếp cận truyền thống với độ phức tạp implementation thấp. BM25 sử dụng Term Frequency-Inverse Document Frequency kết hợp với document length normalization để ranking. Công thức BM25 có dạng:

\begin{equation}
score(D,Q) = \sum_{i=1}^{n} IDF(q_i) \cdot \frac{f(q_i, D) \cdot (k_1 + 1)}{f(q_i, D) + k_1 \cdot (1 - b + b \cdot \frac{|D|}{avgdl})}
\end{equation}

Nhược điểm của BM25 là thiếu khả năng hiểu ngữ nghĩa. Khi người dùng hỏi "làm thêm giờ tối đa bao nhiêu tiếng", hệ thống không thể kết nối với thuật ngữ chính xác trong luật như "法定労働時間" hay "時間外労働の上限規制" do không có token overlap.

\subsection{Phương án 3: RAG (Retrieval-Augmented Generation)}

RAG kết hợp ưu điểm của cả hai phương pháp trên. Retrieval step sử dụng dense embedding để tìm kiếm theo ngữ nghĩa, sau đó LLM sinh câu trả lời dựa trên context được retrieve. Điểm mấu chốt là mọi câu trả lời đều được grounding vào dữ liệu thực, giảm thiểu hiện tượng hallucination. Kiến thức có thể được cập nhật chỉ bằng cách re-index mà không cần re-train model.

Em quyết định chọn RAG vì nó phù hợp nhất với yêu cầu của bài toán: cần trích dẫn nguồn chính xác, cần cập nhật được, và cần xử lý cross-lingual query.

\section{Phạm vi và nguồn dữ liệu}

Đồ án tập trung vào bốn lĩnh vực pháp luật tài chính mà người Việt tại Nhật thường xuyên cần tra cứu nhất:

\begin{itemize}
    \item \textbf{Thuế (税金):} 所得税法 (Luật Thuế thu nhập), 地方税法 (Luật Thuế địa phương), các quy định về 確定申告 (khai thuế cuối năm)
    \item \textbf{Bảo hiểm xã hội (社会保険):} 健康保険法 (Luật Bảo hiểm y tế), 厚生年金保険法 (Luật Bảo hiểm hưu trí), 雇用保険法 (Luật Bảo hiểm thất nghiệp)
    \item \textbf{Đầu tư và tiết kiệm:} NISA (少額投資非課税制度), iDeCo (個人型確定拠出年金)
    \item \textbf{Lao động:} 労働基準法 (Luật Tiêu chuẩn Lao động), 労働契約法 (Luật Hợp đồng Lao động)
\end{itemize}

Nguồn dữ liệu được lấy từ e-Gov Laws API, cổng thông tin pháp luật chính thức của Chính phủ Nhật Bản. Sau quá trình thu thập và lọc, tổng cộng 431 văn bản luật với 206,014 chunks được index vào hệ thống.

% ===================================================
% CHƯƠNG 2: BÁO CÁO CÔNG VIỆC
% ===================================================
\chapter{BÁO CÁO CÔNG VIỆC}

\section{Tổng quan hệ thống (System Overview)}

\subsection{Kiến trúc tổng thể}

Hệ thống được thiết kế theo kiến trúc RAG (Retrieval-Augmented Generation) với hai luồng xử lý chính: \textbf{luồng offline} (data ingestion pipeline) và \textbf{luồng online} (query processing pipeline).

\textbf{Luồng Offline - Data Ingestion:}
\begin{enumerate}
    \item e-Gov REST API $\rightarrow$ GET /law\_data/\{id\}
    \item XML Download (rate limit 1.2s)
    \item XML Parser $\rightarrow$ hierarchical JSON
    \item Paragraph-level Chunking
    \item Dense Embedding (OpenAI 3072-dim) + Sparse Embedding (fastembed BM25)
    \item Qdrant Cloud (Hybrid Collection) + Neo4j (Law Graph)
\end{enumerate}

\textbf{Luồng Online - Query Processing:}
\begin{enumerate}
    \item User Query (Vietnamese) $\rightarrow$ Query Translator + Expansion
    \item Multi-query $\rightarrow$ Batch Embedding
    \item Dense + Sparse $\rightarrow$ Hybrid Search (RRF Fusion)
    \item Top-k candidates $\rightarrow$ Reranker (optional: BGE-reranker-large)
    \item LLM Generation (GPT-4o-mini) $\rightarrow$ Answer + Sources
\end{enumerate}

\subsection{Các thành phần chính}

\begin{table}[H]
\centering
\caption{Các thành phần chính của hệ thống}
\begin{tabular}{|l|l|l|}
\hline
\textbf{Thành phần} & \textbf{Công nghệ} & \textbf{Mục đích} \\
\hline
Data Collection & Python + httpx & Thu thập văn bản luật từ e-Gov API \\
\hline
Data Processing & lxml + custom parser & Parse XML và chunking \\
\hline
Vector Store & Qdrant Cloud & Lưu trữ và tìm kiếm vector \\
\hline
Graph Database & Neo4j Aura & Lưu trữ knowledge graph \\
\hline
Embedding & OpenAI text-embedding-3-large & Vector hóa text \\
\hline
LLM & GPT-4o-mini & Dịch query và sinh câu trả lời \\
\hline
Backend & FastAPI & REST API server \\
\hline
Frontend & Next.js & Giao diện người dùng \\
\hline
\end{tabular}
\end{table}

\subsection{Luồng xử lý dữ liệu}

\begin{itemize}
    \item \textbf{Luồng offline:} Chỉ cần chạy một lần khi có dữ liệu mới hoặc cập nhật. Bao gồm thu thập $\rightarrow$ parse $\rightarrow$ chunk $\rightarrow$ embed $\rightarrow$ index.
    \item \textbf{Luồng online:} Xử lý mỗi query từ người dùng, target latency dưới 10 giây.
\end{itemize}

\section{Xử lý dữ liệu (Data Processing)}

\subsection{Thu thập dữ liệu từ e-Gov API}

\subsubsection{Phân tích API và chiến lược thu thập}

e-Gov Laws API cung cấp ba endpoint chính:

\begin{table}[H]
\centering
\caption{Các endpoint của e-Gov Laws API}
\begin{tabular}{|l|l|l|l|}
\hline
\textbf{Endpoint} & \textbf{Method} & \textbf{Mục đích} & \textbf{Rate Limit} \\
\hline
/laws & GET & Lấy danh sách luật theo category & $\sim$50 req/min \\
\hline
/keyword & GET & Tìm kiếm theo keyword & $\sim$50 req/min \\
\hline
/law\_data/\{law\_id\} & GET & Download nội dung XML & $\sim$50 req/min \\
\hline
\end{tabular}
\end{table}

Hai chiến lược thu thập bổ sung nhau:

\textbf{Category-based search:} Query theo 4 category tài chính là 国税 (thuế quốc gia), 地方財政 (tài chính địa phương), 社会保険 (bảo hiểm xã hội), và 労働 (lao động).

\textbf{Keyword-based search:} Search các keyword liên quan đến người nước ngoài như 外国人, 在留, 所得税, 年金, 健康保険.

\subsubsection{Bộ lọc chất lượng}

Ba bộ lọc được áp dụng:
\begin{itemize}
    \item \textbf{Era filter:} Chỉ lấy luật từ thời Showa (1926) trở về sau
    \item \textbf{Law type filter:} Tập trung vào Act (法律) và Cabinet Order (政令)
    \item \textbf{Status filter:} Chỉ lấy luật có trạng thái CurrentEnforced (現行有効)
\end{itemize}

\subsubsection{Xử lý rate limiting}
\begin{itemize}
    \item \textbf{Request delay:} 1.2 giây giữa mỗi request
    \item \textbf{Exponential backoff:} Retry sau 5s, 10s, 20s nếu fail
    \item \textbf{Checkpoint saving:} Resume nếu bị interrupt
\end{itemize}

\textbf{Kết quả:} 431 files XML ($\sim$80MB) được download thành công.

\subsection{XML Parsing}

\subsubsection{Cấu trúc XML e-Gov}

\begin{lstlisting}[language=XML, caption={Cấu trúc XML e-Gov Laws}]
law_data
├── law_info (metadata: law_id, law_type, promulgation_date)
├── revision_info (law_title, category, current_status)
└── law_full_text
    └── Law
        └── LawBody
            ├── TOC (mục lục)
            ├── MainProvision (phần chính)
            │   ├── Part → Chapter → Section → Article
            │   └── Article → Paragraph → Sentence/Item
            └── SupplProvision (điều khoản chuyển tiếp)
\end{lstlisting}

\subsubsection{Trích xuất metadata}

\begin{table}[H]
\centering
\caption{Các trường metadata được trích xuất}
\begin{tabular}{|l|l|l|l|}
\hline
\textbf{Field} & \textbf{Source} & \textbf{Ví dụ} & \textbf{Purpose} \\
\hline
law\_id & law\_info & 411AC0000000073 & Unique identifier \\
\hline
law\_title & revision\_info & 所得税法 & Display name \\
\hline
law\_type & law\_info & Act & Quality filter \\
\hline
promulgation\_date & law\_info & 1965-03-31 & Temporal info \\
\hline
\end{tabular}
\end{table}

\subsection{Chiến lược Chunking}

\subsubsection{Đánh giá các phương án}

\begin{table}[H]
\centering
\caption{So sánh các phương án chunking}
\begin{tabular}{|l|l|l|}
\hline
\textbf{Phương án} & \textbf{Ưu điểm} & \textbf{Nhược điểm} \\
\hline
Fixed-size (512 tokens) & Đồng đều & Phá vỡ semantic coherence \\
\hline
Sentence-level & Granular & Quá nhỏ, mất context \\
\hline
Article-level & Context đầy đủ & Quá lớn (>2000 tokens) \\
\hline
\textbf{Paragraph-level} & Mapping với citation format & \textbf{Được chọn} \\
\hline
\end{tabular}
\end{table}

\subsubsection{Context enrichment strategy}

Hai phiên bản text cho mỗi chunk:
\begin{itemize}
    \item \texttt{text}: Nội dung thuần, dùng để hiển thị
    \item \texttt{text\_with\_context}: Prefix với \texttt{\{law\_title\} \{article\_title\}}, dùng để embedding
\end{itemize}

\begin{lstlisting}[caption={Ví dụ context enrichment}]
text: "使用者は、労働者に、休憩時間を除き一週間について
      四十時間を超えて、労働させてはならない。"

text_with_context: "労働基準法 第三十二条 (労働時間) 使用者は..."
\end{lstlisting}

\subsubsection{Thống kê chunking}

\begin{table}[H]
\centering
\caption{Thống kê kết quả chunking}
\begin{tabular}{|l|r|}
\hline
\textbf{Metric} & \textbf{Value} \\
\hline
Total Laws & 431 \\
\hline
Total Chunks & 206,014 \\
\hline
Avg Chunk Size & $\sim$171 chars ($\sim$85 tokens) \\
\hline
\end{tabular}
\end{table}

\subsection{Embedding}

\subsubsection{Dense Embedding}

\begin{table}[H]
\centering
\caption{So sánh các embedding model}
\begin{tabular}{|l|r|r|}
\hline
\textbf{Model} & \textbf{Dimensions} & \textbf{Cross-lingual Score} \\
\hline
OpenAI text-embedding-3-large & 3072 & \textbf{0.82} \\
\hline
OpenAI text-embedding-3-small & 1536 & 0.71 \\
\hline
Cohere embed-multilingual-v3 & 1024 & 0.75 \\
\hline
\end{tabular}
\end{table}

\texttt{text-embedding-3-large} được chọn vì chất lượng cross-lingual Vietnamese-Japanese vượt trội.

\subsubsection{Sparse Embedding}

Sparse embedding dựa trên BM25 (thư viện \texttt{fastembed}) bổ sung cho exact term matching như "第三十二条".

\subsubsection{Batch processing}
\begin{itemize}
    \item \textbf{Batch size:} 100 texts per API call
    \item \textbf{Resume capability:} Checkpoint sau mỗi law
    \item \textbf{Tổng thời gian:} $\sim$4-5 giờ cho 206,014 chunks
\end{itemize}

\section{Hệ thống truy vấn (Retrieval System)}

\subsection{Vector Database}

\subsubsection{Lựa chọn Qdrant Cloud}

\begin{table}[H]
\centering
\caption{So sánh các Vector Database}
\begin{tabular}{|l|c|c|l|}
\hline
\textbf{Database} & \textbf{Native Hybrid} & \textbf{Managed} & \textbf{Đánh giá} \\
\hline
Qdrant Cloud & $\checkmark$ RRF Fusion & $\checkmark$ & \textbf{Được chọn} \\
\hline
Pinecone & $\times$ & $\checkmark$ & Cần app-level merge \\
\hline
ChromaDB & $\times$ & $\times$ & Không production-ready \\
\hline
\end{tabular}
\end{table}

\subsubsection{Collection configuration}

\begin{lstlisting}[language=Python, caption={Cấu hình Qdrant Collection}]
# Dense vector config
dense_config = VectorParams(size=3072, distance=Distance.COSINE)

# Sparse vector config  
sparse_config = SparseVectorParams(modifier=Modifier.IDF)

# Hybrid collection
client.create_collection(
    collection_name="japanese_laws_hybrid",
    vectors_config={"dense": dense_config},
    sparse_vectors_config={"sparse": sparse_config},
)
\end{lstlisting}

\subsection{Hybrid Search với RRF}

Reciprocal Rank Fusion merge kết quả từ dense và sparse search:

\begin{equation}
RRF_{score}(d) = \sum_{r \in \{dense, sparse\}} \frac{1}{k + rank_r(d)}
\end{equation}

\textbf{Kết quả:} Hybrid search cải thiện recall +15-20\% so với dense-only.

\subsection{Query Processing Pipeline}

\subsubsection{Query Translation và Expansion}

\textbf{Input:} Query tiếng Việt
\begin{lstlisting}
"Thời gian làm việc tối đa mỗi tuần là bao nhiêu?"
\end{lstlisting}

\textbf{Output (JSON):}
\begin{lstlisting}[language=Python]
{
  "translated": "週の最大労働時間は何時間ですか",
  "keywords": ["法定労働時間", "週40時間", "時間外労働"],
  "search_queries": ["法定労働時間とは", "週の労働時間上限規定"]
}
\end{lstlisting}

\subsubsection{Multi-query Retrieval}
\begin{enumerate}
    \item Embed tất cả search queries trong một batch call
    \item Chạy hybrid search song song
    \item Merge và deduplicate kết quả
    \item Apply score threshold filter (min\_score = 0.25)
\end{enumerate}

\subsection{Two-Stage Retrieval với Reranking}

\subsubsection{Kiến trúc Two-Stage}
\begin{itemize}
    \item \textbf{Stage 1 (Recall):} Bi-encoder hybrid search $\rightarrow$ top 20-40 candidates
    \item \textbf{Stage 2 (Precision):} Cross-encoder rerank $\rightarrow$ top 5 final results
\end{itemize}

\subsubsection{BGE Reranker}

\texttt{BAAI/bge-reranker-large} được sử dụng:
\begin{itemize}
    \item \textbf{Model size:} $\sim$560M parameters
    \item \textbf{Latency:} $\sim$500ms cho 20 documents (CPU)
\end{itemize}

\subsubsection{Benchmark kết quả}

\begin{table}[H]
\centering
\caption{Kết quả benchmark reranking}
\begin{tabular}{|l|r|}
\hline
\textbf{Query} & \textbf{Improvement} \\
\hline
Thời gian nghỉ giữa ca & +32\% \\
\hline
Làm thêm giờ gấp đôi & +8\% \\
\hline
Sa thải trong thử việc & +29\% \\
\hline
\end{tabular}
\end{table}

\subsubsection{Trade-off quyết định}

Reranker bị \textbf{disable by default} vì latency 20-30s không acceptable. Config:
\begin{lstlisting}
USE_RERANKER=false
USE_HYBRID_SEARCH=true
\end{lstlisting}

\subsection{GraphRAG Integration}

\subsubsection{Knowledge Graph Schema (Neo4j)}

\begin{lstlisting}[language=SQL, caption={Schema Neo4j Knowledge Graph}]
(:Law {law_id, law_title, category})
(:Article {article_num, article_title})
(:Paragraph {paragraph_num, text, chunk_id})

(:Law)-[:HAS_ARTICLE]->(:Article)
(:Article)-[:HAS_PARAGRAPH]->(:Paragraph)
(:Article)-[:REFERENCES]->(:Article)
\end{lstlisting}

\subsubsection{Query Router}

\begin{table}[H]
\centering
\caption{Query Router strategies}
\begin{tabular}{|l|l|}
\hline
\textbf{Query Type} & \textbf{Strategy} \\
\hline
SEMANTIC & Vector search only \\
\hline
ENTITY\_LOOKUP & Graph lookup + Vector \\
\hline
MULTI\_HOP & Graph traversal + Vector \\
\hline
\end{tabular}
\end{table}

\section{Sinh câu trả lời (Answer Generation)}

\subsection{LangGraph Agent với Self-Correction}

\subsubsection{Vấn đề với Linear Pipeline}

RAG pipeline cơ bản: translate $\rightarrow$ search $\rightarrow$ generate. Khi search trả về documents không relevant, generate vẫn sinh câu trả lời sai.

\subsubsection{StateGraph Design}

Luồng xử lý của LangGraph Agent:
\begin{enumerate}
    \item \texttt{translate\_node}: Dịch và mở rộng query
    \item \texttt{retrieve\_node}: Tìm kiếm documents
    \item \texttt{grade\_documents\_node}: Đánh giá relevance
    \item Nếu relevant\_count $\geq$ 2: tiếp tục đến \texttt{rerank\_node}
    \item Nếu relevant\_count $<$ 2 và retry $<$ 2: quay lại \texttt{rewrite\_query\_node}
    \item \texttt{rerank\_node}: Xếp hạng lại documents
    \item \texttt{generate\_node}: Sinh câu trả lời
\end{enumerate}

\subsubsection{State definition}

\begin{lstlisting}[language=Python, caption={LegalRAGState definition}]
class LegalRAGState(TypedDict):
    query: str
    translated_query: str
    search_queries: list[str]
    documents: list[dict]
    document_grades: list[str]  # "relevant" | "not_relevant"
    reranked_documents: list[dict]
    answer: str
    sources: list[dict]
    rewrite_count: int
\end{lstlisting}

\subsection{Node Implementations}

\begin{table}[H]
\centering
\caption{Các node trong LangGraph Agent}
\begin{tabular}{|l|l|}
\hline
\textbf{Node} & \textbf{Chức năng} \\
\hline
translate\_node & Query expansion module \\
\hline
retrieve\_node & Multi-query hybrid search \\
\hline
grade\_documents\_node & LLM đánh giá relevance \\
\hline
rewrite\_query\_node & LLM viết lại query \\
\hline
rerank\_node & Cross-encoder reranking \\
\hline
generate\_node & LLM sinh câu trả lời với citations \\
\hline
\end{tabular}
\end{table}

\subsection{Self-correction Logic}

\begin{lstlisting}[language=Python, caption={Self-correction routing logic}]
def should_rewrite(state: LegalRAGState) -> Literal["rerank", "rewrite"]:
    relevant_count = sum(1 for g in state["document_grades"] 
                         if g == "relevant")
    rewrite_count = state.get("rewrite_count", 0)
    
    if relevant_count >= 2 or rewrite_count >= 2:
        return "rerank"
    else:
        return "rewrite"  # Loop back
\end{lstlisting}

Max 2 lần rewrite để tránh infinite loop.

\subsection{Đánh giá với RAGAS}

\subsubsection{Test dataset}

20 câu hỏi covering các topics chính, mỗi câu có ground truth từ luật gốc.

\subsubsection{RAGAS Metrics}

\begin{table}[H]
\centering
\caption{Kết quả RAGAS Evaluation}
\begin{tabular}{|l|r|l|}
\hline
\textbf{Metric} & \textbf{Score} & \textbf{Interpretation} \\
\hline
Context Precision & 0.72 & 72\% retrieved docs relevant \\
\hline
Context Recall & 0.68 & 68\% ground truth covered \\
\hline
\textbf{Faithfulness} & \textbf{0.85} & 85\% answer grounded \\
\hline
Answer Relevancy & 0.78 & 78\% answer addresses query \\
\hline
\end{tabular}
\end{table}

\subsubsection{Configuration comparison}

\begin{table}[H]
\centering
\caption{So sánh các cấu hình}
\begin{tabular}{|l|r|r|}
\hline
\textbf{Configuration} & \textbf{Avg RAGAS} & \textbf{Latency} \\
\hline
Vector only & 0.65 & 3s \\
\hline
Hybrid search & 0.72 & 5s \\
\hline
Hybrid + Rerank & 0.78 & 35s \\
\hline
+ LangGraph Agent & 0.81 & 45s \\
\hline
\end{tabular}
\end{table}

\section{Cài đặt và tối ưu hệ thống (System Setup)}

\subsection{Performance Optimization}

\subsubsection{Initial latency breakdown}

\begin{table}[H]
\centering
\caption{Phân tích latency ban đầu}
\begin{tabular}{|l|r|r|}
\hline
\textbf{Step} & \textbf{Duration} & \textbf{\% Total} \\
\hline
Translation + Expansion & 2s & 3\% \\
\hline
Multi-Query Embedding (5x) & 3s & 5\% \\
\hline
Hybrid Search (5x) & 5s & 8\% \\
\hline
\textbf{Reranking (BGE CPU)} & \textbf{35s} & \textbf{58\%} \\
\hline
Generation & 3s & 5\% \\
\hline
\textbf{Total} & \textbf{60s+} & $\times$ \\
\hline
\end{tabular}
\end{table}

\subsubsection{Optimization steps}

\textbf{Phase 1 - Emergency fix:}
\begin{itemize}
    \item Disable reranker: 60s $\rightarrow$ 15s (-75\%)
    \item Reduce multi-query 5$\rightarrow$2: 15s $\rightarrow$ 10s (-33\%)
\end{itemize}

\textbf{Phase 2 - Query optimization:}
\begin{itemize}
    \item Merge translation + expansion: Giảm 1 LLM roundtrip
    \item Batch embedding: 2 API calls $\rightarrow$ 1
\end{itemize}

\subsubsection{Kết quả final}

\begin{table}[H]
\centering
\caption{Kết quả tối ưu hiệu năng}
\begin{tabular}{|l|r|r|r|}
\hline
\textbf{Metric} & \textbf{Before} & \textbf{After} & \textbf{Improvement} \\
\hline
Avg Latency & 60s+ & 5-6s & \textbf{-90\%} \\
\hline
P95 Latency & 80s & 10s & -87\% \\
\hline
Quality (RAGAS) & 0.78 & 0.72 & -8\% \\
\hline
\end{tabular}
\end{table}

Trade-off 8\% quality để giảm 90\% latency là acceptable cho production.

\subsection{Infrastructure Setup}

\subsubsection{Tech Stack}

\begin{table}[H]
\centering
\caption{Technology Stack}
\begin{tabular}{|l|l|}
\hline
\textbf{Layer} & \textbf{Technology} \\
\hline
Backend & FastAPI + Uvicorn \\
\hline
Frontend & Next.js \\
\hline
Vector DB & Qdrant Cloud \\
\hline
Graph DB & Neo4j Aura \\
\hline
LLM & OpenAI API \\
\hline
\end{tabular}
\end{table}

\subsubsection{Environment Configuration}

\begin{lstlisting}[caption={Environment variables}]
# Qdrant Cloud
QDRANT_URL=https://xxx.cloud.qdrant.io:6333
QDRANT_API_KEY=xxx

# Neo4j Aura
NEO4J_URI=neo4j+s://xxx.databases.neo4j.io
NEO4J_USER=neo4j
NEO4J_PASSWORD=xxx

# OpenAI
OPENAI_API_KEY=sk-xxx

# Performance tuning
USE_RERANKER=false
USE_HYBRID_SEARCH=true
MULTI_QUERY_COUNT=2
\end{lstlisting}

\subsection{Deployment}

\subsubsection{Container packaging}

\begin{lstlisting}[language=bash, caption={Dockerfile}]
FROM python:3.11-slim
WORKDIR /app
COPY requirements.txt .
RUN pip install -r requirements.txt
COPY . .
CMD ["uvicorn", "app.main:app", "--host", "0.0.0.0", "--port", "8000"]
\end{lstlisting}

\subsubsection{Production considerations}
\begin{itemize}
    \item \textbf{Rate limiting:} 100 req/min per IP
    \item \textbf{API key authentication:} Required for production
    \item \textbf{Logging:} Structured JSON format
    \item \textbf{Metrics:} Request latency, error rate, cache hit ratio
\end{itemize}

% ===================================================
% CHƯƠNG 3: HƯỚNG PHÁT TRIỂN TIẾP THEO
% ===================================================
\chapter{HƯỚNG PHÁT TRIỂN TIẾP THEO}

\section{Các hạn chế hiện tại}

Phần này trình bày thành thật về các hạn chế của hệ thống hiện tại:

\textbf{Latency vẫn cao:} 5-6 giây response time vẫn chậm hơn nhiều so với ChatGPT ($\sim$1s). Bottleneck chính là LLM calls (translation + generation) và network latency đến Qdrant Cloud.

\textbf{Coverage cần mở rộng:} 431 luật hiện tại đã cover tốt lĩnh vực tài chính và lao động, nhưng vẫn còn nhiều lĩnh vực quan trọng khác như dân sự (民法), thương mại (商法), xuất nhập cảnh (出入国管理法) có thể bổ sung thêm.

\textbf{Không có conversation memory:} Mỗi query được xử lý độc lập. Người dùng không thể đặt câu hỏi follow-up như "Vậy còn trường hợp ngoại lệ thì sao?".

\textbf{Evaluation chưa đầy đủ:} RAGAS cho metrics tự động nhưng chưa có human evaluation để đánh giá usefulness thực tế.

\textbf{Cross-reference extraction còn sơ sài:} Regex-based extraction bỏ sót nhiều implicit references và các cách diễn đạt phức tạp.

\section{Cải thiện ngắn hạn (1-2 tháng)}

\textbf{Caching layer với Redis:}
\begin{itemize}
    \item Cache query embeddings (TTL 24h)
    \item Cache translation results (TTL 7d)
    \item Cache frequent query responses (invalidate khi có data update)
    \item Expected improvement: Latency $<$ 1s cho cached queries
\end{itemize}

\textbf{Conversation memory:}
\begin{itemize}
    \item Simple approach: Concatenate last N turns vào prompt
    \item Advanced: Maintain summary của conversation history
    \item Implementation: 1-2 tuần development
\end{itemize}

\textbf{Expand dataset:}
\begin{itemize}
    \item Pipeline đã sẵn sàng, chỉ cần thêm categories/keywords
    \item Target: Thêm 民法, 商法, 出入国管理法
    \item Effort: 2-3 ngày data collection + processing
\end{itemize}

\section{Cải thiện dài hạn}

\textbf{GPU-accelerated reranking:}
\begin{itemize}
    \item Deploy trên instance có GPU (T4 hoặc A10)
    \item Expected latency: 35s $\rightarrow$ 2-3s
    \item Cost: $\sim$\$0.5/hour cho on-demand GPU instance
\end{itemize}

\textbf{Fine-tuned embedding model:}
\begin{itemize}
    \item Train adapter layer trên legal domain data
    \item Cần contrastive learning dataset với (query, positive, negative) triplets
    \item Effort: 2-3 tháng research + implementation
\end{itemize}

\textbf{Full GraphRAG với Neo4j:}
\begin{itemize}
    \item NER model cho entity extraction thay vì regex
    \item Relationship classification model
    \item Multi-hop reasoning queries
\end{itemize}

\textbf{Agentic RAG:}
\begin{itemize}
    \item Agent với tools: search, calculate (thuế), lookup (bảng phí)
    \item Handling complex queries cần multiple steps
\end{itemize}

\section{Production deployment considerations}

\textbf{Infrastructure:}
\begin{itemize}
    \item Container packaging với Docker
    \item Kubernetes deployment với autoscaling
    \item CDN cho frontend assets
\end{itemize}

\textbf{Security:}
\begin{itemize}
    \item Rate limiting (100 req/min per IP)
    \item API key authentication
    \item Input sanitization
\end{itemize}

\textbf{Observability:}
\begin{itemize}
    \item Structured logging (JSON format)
    \item Metrics: request latency, error rate, cache hit ratio
    \item Distributed tracing với OpenTelemetry
\end{itemize}

\textbf{Legal disclaimer:}
\begin{itemize}
    \item Hệ thống chỉ cung cấp thông tin tham khảo
    \item Không phải tư vấn pháp lý chính thức
    \item Người dùng nên verify với nguồn chính thức
\end{itemize}

% ===================================================
% CHƯƠNG 4: TỔNG KẾT
% ===================================================
\chapter{TỔNG KẾT}

\section{Những gì đã đạt được}

Qua đồ án này, một hệ thống RAG hoàn chỉnh đã được xây dựng với các thành phần:

\begin{itemize}
    \item \textbf{End-to-end RAG pipeline:} Từ data ingestion đến response generation
    \item \textbf{431 văn bản luật} được index với 206,014 chunks
    \item \textbf{Cross-lingual retrieval:} Vietnamese query $\rightarrow$ Japanese documents
    \item \textbf{Hybrid search:} Kết hợp semantic (dense) và keyword (sparse)
    \item \textbf{Two-stage retrieval:} Bi-encoder + optional cross-encoder reranking
    \item \textbf{LangGraph agent:} Self-correction loop cho complex queries
    \item \textbf{GraphRAG integration:} Knowledge graph với Neo4j
\end{itemize}

Hệ thống đạt \textbf{Faithfulness 0.85} trên RAGAS evaluation, cho thấy câu trả lời được grounding tốt vào context.

\section{Bài học kỹ thuật}

\textbf{Data quality > Model size:}
Chunking strategy phù hợp và context enrichment có impact lớn hơn việc sử dụng embedding model đắt tiền. Paragraph-level chunking với context prefix cải thiện retrieval 15-20\% so với naive fixed-size chunking.

\textbf{Hybrid approach outperforms single method:}
Dense + Sparse embedding, Vector + Graph search, Bi-encoder + Cross-encoder. Combination thường tốt hơn single method.

\textbf{Trade-offs are inevitable:}
Reranker cải thiện quality nhưng với latency cost không acceptable. Biết khi nào nên compromise là quan trọng. Việc disable reranker by default để đảm bảo UX là một quyết định pragmatic.

\textbf{Don't over-engineer early:}
Nhiều optimization như caching, complex agent logic chỉ nên implement khi đã có baseline working và hiểu rõ bottleneck thực sự.

\section{Những điều học được}

Ngoài kiến thức kỹ thuật, đồ án này giúp em hiểu rõ hơn về:

\begin{itemize}
    \item \textbf{System design thinking:} Cân nhắc trade-offs, không có silver bullet
    \item \textbf{Iterative development:} Start simple, measure, optimize
    \item \textbf{Production mindset:} Latency, cost, maintainability matter
    \item \textbf{Domain expertise:} Legal domain có những yêu cầu riêng (citation precision, authority)
\end{itemize}

\section{Kết luận}

Đồ án này là một trải nghiệm học tập quý giá về việc xây dựng hệ thống AI ứng dụng thực tế. Từ việc thu thập dữ liệu, xử lý ngôn ngữ tự nhiên, đến tối ưu hiệu năng, mỗi bước đều có những thách thức và bài học riêng.

Hệ thống chưa hoàn hảo và còn nhiều điểm cần cải thiện. Tuy nhiên, mục tiêu ban đầu đã đạt được: một công cụ giúp người Việt Nam tại Nhật Bản tiếp cận thông tin pháp luật dễ dàng hơn, bằng chính ngôn ngữ của họ, với trích dẫn nguồn chính xác.

% ===================================================
% TÀI LIỆU THAM KHẢO
% ===================================================
\chapter{TÀI LIỆU THAM KHẢO}

\section{Nghiên cứu học thuật}

\begin{enumerate}
    \item Lewis, P., Perez, E., Piktus, A., Petroni, F., Karpukhin, V., Goyal, N., Küttler, H., Lewis, M., Yih, W., Rocktäschel, T., Riedel, S., và Kiela, D. (2020). "Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks." \textit{Proceedings of NeurIPS 2020}.
    
    \item Karpukhin, V., Oğuz, B., Min, S., Lewis, P., Wu, L., Edunov, S., Chen, D., và Yih, W. (2020). "Dense Passage Retrieval for Open-Domain Question Answering." \textit{Proceedings of EMNLP 2020}.
    
    \item Xiao, S., Liu, Z., Shao, Y., và Cao, Z. (2023). "BGE: Towards General Text Embeddings with Multi-stage Contrastive Learning." \textit{arXiv preprint}.
    
    \item Wang, L., Yang, N., và Wei, F. (2023). "Query2doc: Query Expansion with Large Language Models." \textit{Proceedings of EMNLP 2023}.
    
    \item Robertson, S. và Zaragoza, H. (2009). "The Probabilistic Relevance Framework: BM25 and Beyond." \textit{Foundations and Trends in Information Retrieval}, 3(4), 333-389.
    
    \item Edge, D., Trinh, H., Cheng, N., et al. (2024). "From Local to Global: A Graph RAG Approach to Query-Focused Summarization." \textit{arXiv preprint}.
\end{enumerate}

\section{Tài liệu kỹ thuật}

\begin{enumerate}
    \setcounter{enumi}{6}
    \item OpenAI. "Embeddings API Documentation." \url{https://platform.openai.com/docs/guides/embeddings}
    
    \item Qdrant. "Vector Database Documentation." \url{https://qdrant.tech/documentation/}
    
    \item LangGraph. "Build Agentic Workflows." \url{https://langchain-ai.github.io/langgraph/}
    
    \item Neo4j. "Graph Database Documentation." \url{https://neo4j.com/docs/}
    
    \item FastAPI. "Modern Python Web Framework." \url{https://fastapi.tiangolo.com/}
    
    \item RAGAS. "Evaluation Framework for Retrieval Augmented Generation." \url{https://docs.ragas.io/}
\end{enumerate}

\section{Nguồn dữ liệu}

\begin{enumerate}
    \setcounter{enumi}{12}
    \item Bộ Nội vụ và Truyền thông Nhật Bản. "e-Gov Laws API 仕様書." \url{https://elaws.e-gov.go.jp/apitop/}
    
    \item Bộ Tư pháp Nhật Bản. "在留外国人統計." \url{https://www.moj.go.jp/isa/policies/statistics/}
\end{enumerate}

\section{Thư viện và công cụ}

\begin{enumerate}
    \setcounter{enumi}{14}
    \item FlagEmbedding. "BGE Reranker." \url{https://github.com/FlagOpen/FlagEmbedding}
    
    \item fastembed. "Fast Text Embedding Library." \url{https://github.com/qdrant/fastembed}
    
    \item lxml. "XML Processing Library." \url{https://lxml.de/}
\end{enumerate}

\vspace{2cm}
\begin{center}
    \textbf{Norman - Japanese Financial Law RAG System}\\
    Báo cáo Đồ án GR2 | Tháng 1/2026
\end{center}

\end{document}

